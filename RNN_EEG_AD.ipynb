{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnnPhann2204/EEG-AD/blob/main/RNN_EEG_AD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAT6U5gRkpxp",
        "outputId": "e2e9d888-0540-47c2-c09d-41740b48383c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rnn-eeg-ad'...\n",
            "remote: Enumerating objects: 73, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 73 (delta 1), reused 4 (delta 1), pack-reused 65 (from 1)\u001b[K\n",
            "Receiving objects: 100% (73/73), 156.36 MiB | 2.67 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n",
            "Updating files: 100% (46/46), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MAlessandrini-Univpm/rnn-eeg-ad.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asyzcFE3qWY1",
        "outputId": "465fd70b-9dc7-4e27-beec-301ad9c638a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rnn-eeg-ad\n"
          ]
        }
      ],
      "source": [
        "%cd rnn-eeg-ad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spf-AOI_qaJ2",
        "outputId": "af58b5d9-39b8-414b-c6ff-5df2237c84a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_cross_val.py  batch_test.py  LICENSE  mu_golden_search.py  README.md\t   rnn_eeg_ad.py\n",
            "batch_spikes.py     eeg2\t   mspca.m  parse_log.py\t requirements.txt  r_pca.py\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fv7CBsOVrwp0",
        "outputId": "5b49bb10-91b2-4a49-9a3f-56e07e6e1b50"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: absl-py==1.4.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n",
            "Collecting asttokens==2.2.1 (from -r requirements.txt (line 2))\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (1.6.3)\n",
            "Requirement already satisfied: backcall==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.2.0)\n",
            "Collecting cachetools==5.3.0 (from -r requirements.txt (line 5))\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting certifi==2022.12.7 (from -r requirements.txt (line 6))\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting charset-normalizer==3.1.0 (from -r requirements.txt (line 7))\n",
            "  Downloading charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (2.2.1)\n",
            "Collecting comm==0.1.3 (from -r requirements.txt (line 9))\n",
            "  Downloading comm-0.1.3-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting contourpy==1.0.7 (from -r requirements.txt (line 10))\n",
            "  Downloading contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting cycler==0.11.0 (from -r requirements.txt (line 11))\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl.metadata (785 bytes)\n",
            "Requirement already satisfied: debugpy==1.6.6 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.6.6)\n",
            "Collecting decorator==5.1.1 (from -r requirements.txt (line 13))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: entrypoints==0.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.4)\n",
            "Collecting executing==1.2.0 (from -r requirements.txt (line 15))\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting flatbuffers==23.3.3 (from -r requirements.txt (line 16))\n",
            "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl.metadata (849 bytes)\n",
            "Collecting fonttools==4.39.2 (from -r requirements.txt (line 17))\n",
            "  Downloading fonttools-4.39.2-py3-none-any.whl.metadata (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.3/145.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gast==0.4.0 (from -r requirements.txt (line 18))\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting google-auth==2.16.3 (from -r requirements.txt (line 19))\n",
            "  Downloading google_auth-2.16.3-py2.py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting google-auth-oauthlib==0.4.6 (from -r requirements.txt (line 20))\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: google-pasta==0.2.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (0.2.0)\n",
            "Collecting grpcio==1.51.3 (from -r requirements.txt (line 22))\n",
            "  Downloading grpcio-1.51.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting h5py==3.8.0 (from -r requirements.txt (line 23))\n",
            "  Downloading h5py-3.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting idna==3.4 (from -r requirements.txt (line 24))\n",
            "  Downloading idna-3.4-py3-none-any.whl.metadata (9.8 kB)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement install==1.3.5 (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for install==1.3.5\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"rnn_eeg_ad.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/1FBmQpdnbDciF9MQvoUXJfnqS6Kvk6oB-\n",
        "\n",
        "**First block of code with imports and function definitions, to be executed only once:**\n",
        "\"\"\"\n",
        "\n",
        "# Commented out IPython magic to ensure Python compatibility.\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, Softmax, Dropout, Bidirectional\n",
        "import scipy.io  # to load/save MAT files\n",
        "import time\n",
        "import datetime\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "import sklearn.decomposition\n",
        "import sklearn.model_selection\n",
        "import sys\n",
        "import os\n",
        "# %matplotlib inline\n",
        "# %load_ext tensorboard\n",
        "\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print('Tf Keras:', keras.__version__)\n",
        "print('TensorFlow:', tf.__version__)\n",
        "print('GPU device:', tf.test.gpu_device_name())\n",
        "\n",
        "if 'google.colab' in sys.modules:  # try to detect if we're running in colab or locally\n",
        "  # working_dir = '/content/drive/MyDrive/Colab Notebooks'\n",
        "  working_dir = '/content/rnn-eeg-ad'\n",
        "#   %cp '/content/drive/MyDrive/Colab Notebooks/r_pca.py' .\n",
        "else:\n",
        "  working_dir = '.'\n",
        "\n",
        "import r_pca\n",
        "#import mspca\n",
        "multiscale_pca = False  # Compute MSPCA before PCA\n",
        "\n",
        "log_dir_base = working_dir + '/logs/fit'\n",
        "\n",
        "num_classes = 2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMZl0zpH1sUd",
        "outputId": "878eebe5-dcd8-4980-dd8b-c8625c801dce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tf Keras: 3.4.1\n",
            "TensorFlow: 2.17.0\n",
            "GPU device: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_dataset(window, overlap, decimation_factor = 0):\n",
        "  # Create the input and target data from dataset,\n",
        "  # according to window and overlap\n",
        "  # new dataset 4 dec 2021\n",
        "  # 15 N, 20 AD (resulting indexes: N = 0..14, AD = 15..34)\n",
        "  #Common signals: ['EEG Fp1', 'EEG Fp2', 'EEG F7', 'EEG F3', 'EEG F4', 'EEG F8', 'EEG T3', 'EEG C3', 'EEG C4', 'EEG T4', 'EEG T5', 'EEG P3', 'EEG P4', 'EEG T6', 'EEG O1', 'EEG O2']\n",
        "\n",
        "  tf.random.set_seed(42)\n",
        "  np.random.seed(42)\n",
        "  dataset_dir = working_dir + '/eeg2'\n",
        "  subj_list = tuple((f'{i:02d}', 'N') for i in range(1, 16)) + tuple((f'{i:02d}', 'AD') for i in range(1, 21))\n",
        "  print(subj_list)\n",
        "  num_columns = 16\n",
        "\n",
        "  x_data = np.empty((0, window, num_columns))\n",
        "  y_data = np.empty((0, 1))  # labels\n",
        "  subj_inputs = []  # number of inputs for every subject\n",
        "  print('\\n### creating dataset')\n",
        "  tot_rows = 0\n",
        "  for subject in subj_list:\n",
        "    subj_inputs.append(0)\n",
        "    category = ('N', 'AD').index(subject[1])\n",
        "    eeg = np.load(f'{dataset_dir}/S{subject[0]}_{subject[1]}.npz')['eeg'].T\n",
        "    if spikes: eeg = set_holes(eeg, spikes)\n",
        "    #scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    scaler = StandardScaler()\n",
        "    eeg = scaler.fit_transform(eeg)\n",
        "    assert(eeg.shape[1] == num_columns)\n",
        "    tot_rows += len(eeg)\n",
        "    # decimation (optional)\n",
        "    if decimation_factor:\n",
        "      eeg2 = np.empty((eeg.shape[0] // decimation_factor, eeg.shape[1]))\n",
        "      for col in range(0, num_columns):\n",
        "        #tmp = scipy.signal.decimate(fusion[:, col], decimation_factor)\n",
        "        tmp = eeg[:, col][::decimation_factor]  # simpler method\n",
        "        eeg2[:, col] = tmp[:len(eeg2)]\n",
        "      eeg = eeg2\n",
        "    # windowing\n",
        "    # compute number of windows (lazy way)\n",
        "    i = 0\n",
        "    num_w = 0\n",
        "    while i + window  <= len(eeg):\n",
        "      i += (window - overlap)\n",
        "      num_w += 1\n",
        "    # compute actual windows\n",
        "    x_data_part = np.empty((num_w, window, num_columns))  # preallocate\n",
        "    i = 0\n",
        "    for w in range(0, num_w):\n",
        "      x_data_part[w] = eeg[i:i + window]\n",
        "      i += (window - overlap)\n",
        "      if False: # watermark provenience of every window\n",
        "        for cc in range(0, num_columns):\n",
        "          x_data_part[w, 0, cc] = 1000 * (len(subj_inputs) - 1) + cc\n",
        "    x_data = np.vstack((x_data, x_data_part))\n",
        "    y_data = np.vstack((y_data, np.full((num_w, 1), category)))\n",
        "    subj_inputs[-1] += num_w\n",
        "\n",
        "  print('\\ntot samples:', tot_rows)\n",
        "  print('x_data:', x_data.shape)\n",
        "  print('y_data:', y_data.shape)\n",
        "  print('windows per subject:', subj_inputs)\n",
        "  print('class distribution:', [np.sum(y_data == cl) for cl in range(0, num_classes)])\n",
        "\n",
        "  return x_data, y_data, subj_inputs"
      ],
      "metadata": {
        "id": "WR9vhF_O1pyS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# def create_dataset(window, overlap, batch_size=32, decimation_factor = 0):\n",
        "#   # Create the input and target data from dataset,\n",
        "#   # according to window and overlap\n",
        "#   # new dataset 4 dec 2021\n",
        "#   # 15 N, 20 AD (resulting indexes: N = 0..14, AD = 15..34)\n",
        "#   #Common signals: ['EEG Fp1', 'EEG Fp2', 'EEG F7', 'EEG F3', 'EEG F4', 'EEG F8', 'EEG T3', 'EEG C3', 'EEG C4', 'EEG T4', 'EEG T5', 'EEG P3', 'EEG P4', 'EEG T6', 'EEG O1', 'EEG O2']\n",
        "\n",
        "#   tf.random.set_seed(42)\n",
        "#   np.random.seed(42)\n",
        "\n",
        "#   dataset_dir = working_dir + '/eeg2'\n",
        "#   subj_list = tuple((f'{i:02d}', 'N') for i in range(1, 16)) + tuple((f'{i:02d}', 'AD') for i in range(1, 21))\n",
        "#   print(subj_list)\n",
        "\n",
        "#   num_columns = 16\n",
        "#   x_data = np.empty((0, window, num_columns), dtype=np.float32)\n",
        "#   y_data = np.empty((0, 1), dtype=np.float32)  # labels\n",
        "#   subj_inputs = []  # number of inputs for every subject\n",
        "\n",
        "#   print('\\n### creating dataset')\n",
        "#   tot_rows = 0\n",
        "#   for subject in subj_list:\n",
        "#     subj_inputs.append(0)\n",
        "#     category = ('N', 'AD').index(subject[1])\n",
        "#     eeg = np.load(f'{dataset_dir}/S{subject[0]}_{subject[1]}.npz')['eeg'].T\n",
        "\n",
        "#     if spikes:\n",
        "#       eeg = set_holes(eeg, spikes)\n",
        "\n",
        "#     #scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "#     scaler = StandardScaler()\n",
        "#     eeg = scaler.fit_transform(eeg).astype(np.float32)\n",
        "#     # assert(eeg.shape[1] == num_columns)\n",
        "#     tot_rows += len(eeg)\n",
        "\n",
        "#     # decimation (optional)\n",
        "#     if decimation_factor:\n",
        "#       eeg2 = np.empty((eeg.shape[0] // decimation_factor, eeg.shape[1]))\n",
        "#       for col in range(0, num_columns):\n",
        "#         #tmp = scipy.signal.decimate(fusion[:, col], decimation_factor)\n",
        "#         tmp = eeg[:, col][::decimation_factor]  # simpler method\n",
        "#         eeg2[:, col] = tmp[:len(eeg2)]\n",
        "#       eeg = eeg2\n",
        "#     # windowing\n",
        "#     # compute number of windows (lazy way)\n",
        "\n",
        "#     num_samples = len(eeg)\n",
        "#     num_windows = 0\n",
        "\n",
        "#     # Create windows\n",
        "#     for start in range(0, num_samples - window + 1, (window - overlap)):\n",
        "#         x_window = eeg[start:start + window]\n",
        "#         y_window = np.array([[category]], dtype=np.float32)  # Labels as float32\n",
        "\n",
        "#         x_data.append(x_window)  # Add new window\n",
        "#         y_data.append(y_window)   # Add corresponding label\n",
        "\n",
        "#         num_windows += 1\n",
        "\n",
        "#         # If we reach the batch size, yield the batch\n",
        "#         if num_windows % batch_size == 0:\n",
        "#             yield (np.array(x_data[-batch_size:]), np.array(y_data[-batch_size:]), subj_inputs)\n",
        "#             x_data, y_data = [], []  # Clear for the next batch\n",
        "\n",
        "#     subj_inputs[-1] += num_windows\n",
        "\n",
        "#   # Yield any remaining data that didn't fill a full batch\n",
        "#   if x_data:\n",
        "#     yield (np.array(x_data), np.array(y_data), subj_inputs)\n",
        "#     # i = 0\n",
        "#     # num_w = 0\n",
        "#     # while i + window  <= len(eeg):\n",
        "#     #   i += (window - overlap)\n",
        "#     #   num_w += 1\n",
        "#     # # compute actual windows\n",
        "#     # x_data_part = np.empty((num_w, window, num_columns))  # preallocate\n",
        "#     # i = 0\n",
        "#     # for w in range(0, num_w):\n",
        "#     #   x_data_part[w] = eeg[i:i + window]\n",
        "#     #   i += (window - overlap)\n",
        "#     #   if False: # watermark provenience of every window\n",
        "#     #     for cc in range(0, num_columns):\n",
        "#     #       x_data_part[w, 0, cc] = 1000 * (len(subj_inputs) - 1) + cc\n",
        "#     # x_data = np.vstack((x_data, x_data_part))\n",
        "#     # y_data = np.vstack((y_data, np.full((num_w, 1), category)))\n",
        "#     # subj_inputs[-1] += num_w\n",
        "\n",
        "#   print('\\ntot samples tot_rows:', tot_rows)\n",
        "#   print('x_data:', x_data.shape)\n",
        "#   print('y_data:', y_data.shape)\n",
        "#   print('windows per subject:', subj_inputs)\n",
        "#   print('class distribution:', [np.sum(y_data == cl) for cl in range(0, num_classes)])\n",
        "#   print('\\nTotal samples y_data:', len(y_data))\n",
        "#   # # Randomly select indices for the batch\n",
        "#   # indices = np.random.choice(len(x_data), size=32, replace=False)\n",
        "#   # # Create batches\n",
        "#   # x_data = x_data[indices]\n",
        "#   # y_data = y_data[indices]\n",
        "\n",
        "#   return x_data, y_data, subj_inputs\n"
      ],
      "metadata": {
        "id": "YFrmZMcb1x6B"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_holes(A, prob):\n",
        "  for i in range(0, len(A)):\n",
        "    if np.random.rand() < prob:\n",
        "      l = 20\n",
        "      l = int(np.random.normal(l, l / 2))\n",
        "      A[i:i+l,:] = 0\n",
        "  return A\n",
        "\n",
        "\n",
        "def partition_data(subjects):\n",
        "  # subjects = tuple (0-based)\n",
        "  x_part = None\n",
        "  y_part = None\n",
        "  subj_inputs_part = []\n",
        "  for subj in subjects:\n",
        "    subj_inputs_part.append(subj_inputs[subj])\n",
        "    skip = sum(subj_inputs[:subj])\n",
        "    num = subj_inputs[subj]\n",
        "    xx = x_data[skip : skip + num]\n",
        "    yy = y_data[skip : skip + num]\n",
        "    if x_part is None:\n",
        "      x_part = xx.copy()\n",
        "      y_part = yy.copy()\n",
        "    else:\n",
        "      x_part = np.vstack((x_part, xx))  # vstack creates a copy of the data\n",
        "      y_part = np.vstack((y_part, yy))\n",
        "  return x_part, y_part, subj_inputs_part\n",
        "\n",
        "\n",
        "def oversampling(x_data, y_data):\n",
        "  # Duplicate inputs with classes occurring less, so to have a more balanced distribution.\n",
        "  # It operates on single data windows, so use it on data that have already been split\n",
        "  #  by subject (typically only on training data).\n",
        "  x_data_over = x_data.copy()\n",
        "  y_data_over = y_data.copy()\n",
        "  occurr = [np.sum(y_data == cl) for cl in range(0, num_classes)]\n",
        "  for cl in range(0, num_classes):\n",
        "    if occurr[cl] == max(occurr):\n",
        "      continue\n",
        "    mask = y_data[:, 0] == cl\n",
        "    x_dup = x_data[mask].copy()\n",
        "    y_dup = y_data[mask].copy()\n",
        "    while occurr[cl] < max(occurr):\n",
        "      x_dup_jitter = x_dup + np.random.normal(scale=0.03, size=x_dup.shape)\n",
        "      how_many = min(len(y_dup), max(occurr) - occurr[cl])\n",
        "      x_data_over = np.vstack((x_data_over, x_dup_jitter[:how_many]))\n",
        "      y_data_over = np.vstack((y_data_over, y_dup[:how_many]))\n",
        "      occurr[cl] += how_many\n",
        "  return x_data_over, y_data_over\n",
        "\n",
        "\n",
        "def create_model(sample_window, dense1, lstm1, lstm2, lstm3 = 0, dropout = 0.2):\n",
        "  print(\"\\n### creating model\")\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.Input(shape = sample_window.shape, name = 'input'))\n",
        "  if dense1: model.add(Dense(dense1, name = 'dense1'))\n",
        "  #model.add(BatchNormalization(name = 'norm1'))\n",
        "  #model.add(Dropout(dropout, name = 'drop1'))\n",
        "  model.add(LSTM(lstm1, return_sequences = bool(lstm2), name = 'lstm1'))\n",
        "  if lstm2:\n",
        "    model.add(Dropout(dropout, name = 'drop2'))\n",
        "    model.add(LSTM(lstm2, return_sequences = bool(lstm3), name = 'lstm2'))\n",
        "  if lstm3:\n",
        "    model.add(Dropout(dropout, name = 'drop4'))\n",
        "    model.add(LSTM(lstm3, name = 'lstm3'))\n",
        "  model.add(Dropout(dropout, name = 'drop3'))\n",
        "  model.add(Dense(num_classes, name = 'dense2'))\n",
        "  model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
        "    optimizer = 'adam', metrics = ['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n",
        "\n",
        "\n",
        "def pca_reduction(A, tol, comp = 0):\n",
        "  assert(len(A.shape) == 2)\n",
        "  dmin = min(A.shape)\n",
        "  if rpca:\n",
        "    r = r_pca.R_pca(A, mu = rpca_mu)\n",
        "    print('Auto tol:', 1e-7 * r.frobenius_norm(r.D), 'used tol:', tol)\n",
        "    print('mu', r.mu, 'lambda', r.lmbda)\n",
        "    L, S = r.fit(tol = tol, max_iter = 10, iter_print = 1)\n",
        "    global norm_s\n",
        "    norm_s = np.linalg.norm(S, ord='fro')  # for debug\n",
        "    print('||A,L,S||:', np.linalg.norm(A, ord='fro'), np.linalg.norm(L, ord='fro'), np.linalg.norm(S, ord='fro'))\n",
        "    #np.savez_compressed('rpca.npz', pre = A, post = L)\n",
        "  elif multiscale_pca:\n",
        "    print('MSPCA...')\n",
        "    #ms = mspca.MultiscalePCA()\n",
        "    #L = ms.fit_transform(A, wavelet_func='sym4', threshold=0.1, scale = True )\n",
        "    print('saving MAT file and calling Matlab...')\n",
        "    scipy.io.savemat('mspca.mat', {'A': A}, do_compression = True)\n",
        "    os.system('matlab -batch \"mspca(\\'mspca.mat\\')\"')\n",
        "    L = scipy.io.loadmat('mspca.mat')['L']\n",
        "  else:\n",
        "    L = A\n",
        "  U, lam, V = np.linalg.svd(L, full_matrices = False)  # V is transposed\n",
        "  assert(U.shape == (A.shape[0], dmin) and lam.shape == (dmin,) and V.shape == (dmin, A.shape[1]))\n",
        "  #np.savetxt('singular_values.csv', lam)\n",
        "  lam_trunc = lam[lam > 0.015 * lam[0]]  # magic number\n",
        "  p = comp if comp else len(lam_trunc)\n",
        "  assert(p <= dmin)\n",
        "  print('PCA truncation', dmin, '->', p)\n",
        "  return L, V.T[:,:p]\n",
        "\n",
        "\n",
        "def reduce_matrix(A, V):\n",
        "  # (N, w, 16) → (N, 16, w) → ((N*16), w) → compute V\n",
        "  # (N, 16, w) * V → transpose again last dimensions\n",
        "  B = np.swapaxes(A, 1, 2)  # (N, 16, w)\n",
        "  C = B.reshape((-1, B.shape[2]))  # ((N*16), w)\n",
        "  if V is None:\n",
        "    L, V = pca_reduction(C, 5e-6, comp = 50)\n",
        "  B = C @ V  # ((N*16), p)\n",
        "  B = B.reshape((A.shape[0], A.shape[2], B.shape[1]))  # (N, 16, p)\n",
        "  return np.swapaxes(B, 1, 2), V  # B = (N, p, 16)\n",
        "\n",
        "\n",
        "def adjust_size(x, y):\n",
        "  # when flattening the data matrix on the first dimension, y must be made compatible\n",
        "  if len(x) == len(y): return y\n",
        "  factor = len(x) // len(y)\n",
        "  ynew = np.empty((len(x), 1))\n",
        "  for i in range(0, len(y)):\n",
        "    ynew[i * factor : (i + 1) * factor] = y[i]\n",
        "  return ynew\n"
      ],
      "metadata": {
        "id": "ck7mkI-OvbYh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_session(save_model = False, load_model = None, write_report = True, file_id = '', earlystop = 0, train_split = 0.75):\n",
        "  def write_values():\n",
        "    print(time.strftime('%H:%M:%S'), file = out_f)\n",
        "    print('window', window, 'overlap', overlap, 'decimation', decimation, file = out_f)\n",
        "    print('layers', dense1, lstm1, lstm2, lstm3, file = out_f)\n",
        "    print('oversample', oversample, file = out_f)\n",
        "    print('pca', pca, file = out_f)\n",
        "    print('rpca', rpca, file = out_f)\n",
        "    print('mspca', multiscale_pca, file = out_f)\n",
        "    print('subj_train', permutation, file = out_f)\n",
        "    print('epochs', epochs, file = out_f)\n",
        "    if history is not None:\n",
        "      print('fit_accuracy', [round(x, 4) for x in history.history['accuracy']], file = out_f)\n",
        "    if history is not None and 'val_accuracy' in history.history:\n",
        "      print('fit_val_accuracy', [round(x, 4) for x in history.history['val_accuracy']], file = out_f)\n",
        "    print('subj_test', subjs_test[perm_index] if subjs_test and type(subjs_test[0]) == tuple else subjs_test, file = out_f)\n",
        "    if subjs_test: print('test_accuracy', round(eval_metrics[1], 4), file = out_f)\n",
        "    print('permutation', perm_index + 1, file = out_f)\n",
        "    print('train_size', len(x_data_train), file = out_f)\n",
        "    print('p', 0 if Vpca is None else Vpca.shape[1], file = out_f)\n",
        "    print('spikes', spikes, file = out_f)\n",
        "    print('time_train', time_train, file = out_f)\n",
        "    if subjs_test: print('time_test', time_test, file = out_f)\n",
        "    print(file = out_f)\n",
        "    out_f.flush()\n",
        "\n",
        "  if write_report:\n",
        "    output_file = time.strftime('%Y%m%d-%H%M%S') + file_id + '.txt'\n",
        "    out_f = open(working_dir + '/' + output_file, 'w')\n",
        "  # tensorboard stuff\n",
        "  #%rm -rf \"$log_dir_base\"\n",
        "  log_dir = log_dir_base + '/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
        "  for perm_index, permutation in enumerate(subjs_train_perm):\n",
        "    assert(type(permutation) == tuple)\n",
        "    assert(len(permutation) == 2)\n",
        "    assert(type(permutation[0]) == tuple)\n",
        "    assert(type(permutation[1]) == tuple)\n",
        "    assert(type(subjs_test) == tuple)\n",
        "    tf.random.set_seed(42)\n",
        "    np.random.seed(42)\n",
        "    x_data_train, y_data_train, _ = partition_data(permutation[0])  # train subjects\n",
        "    x_data_val, y_data_val, _ = partition_data(permutation[1])  # validation subjects, can be None\n",
        "    if oversample:\n",
        "      print('\\nclass distribution (training subset):', [np.sum(y_data_train == cl) for cl in range(0, num_classes)])\n",
        "      x_data_train, y_data_train = oversampling(x_data_train, y_data_train)\n",
        "      print('After oversampling (training subset):')\n",
        "      print('x_data_train:', x_data_train.shape)\n",
        "      print('y_data_train:', y_data_train.shape)\n",
        "      print('class distribution:', [np.sum(y_data_train == cl) for cl in range(0, num_classes)])\n",
        "    if False:\n",
        "      #for i in range(0, len(x_data_train)):\n",
        "      #  x_data_train[i] = set_holes(x_data_train[i], spikes)\n",
        "      for w in range(0, len(x_data_train)):  # every window\n",
        "        for c in range(0, x_data_train.shape[2]):  # every column\n",
        "          if np.random.rand() < spikes:\n",
        "            t = 1\n",
        "            for r in range(0, x_data_train.shape[1] // 2):\n",
        "              x_data_train[w, r + x_data_train.shape[1] // 4 , c] = t\n",
        "              t *= -1\n",
        "    # if train_split != 0, we ignore the provided x_data_val and split training in training + validation (Laura)\n",
        "    if train_split:\n",
        "      x_data_train, x_data_val, y_data_train, y_data_val = sklearn.model_selection.train_test_split(x_data_train, y_data_train, train_size = train_split, random_state=42, shuffle=True)\n",
        "    #\n",
        "    #np.savez_compressed('x_data_train.npz', x_data_train = x_data_train)\n",
        "    #print('x_data_train saved')\n",
        "    if pca:\n",
        "      print('\\nPerforming (R)(MS)PCA...')\n",
        "      x_data_train, Vpca = reduce_matrix(x_data_train, None)\n",
        "      y_data_train = adjust_size(x_data_train, y_data_train)\n",
        "      if x_data_val is not None:\n",
        "        x_data_val, _ = reduce_matrix(x_data_val, Vpca)\n",
        "        y_data_val = adjust_size(x_data_val, y_data_val)\n",
        "      print('x_data_train:', x_data_train.shape)\n",
        "      print('y_data_train:', y_data_train.shape, [np.sum(y_data_train == cl) for cl in range(0, num_classes)])\n",
        "      if x_data_val is not None:\n",
        "        print('x_data_val:', x_data_val.shape)\n",
        "        print('y_data_val:', y_data_val.shape, [np.sum(y_data_val == cl) for cl in range(0, num_classes)])\n",
        "    else:\n",
        "      Vpca = None\n",
        "    if load_model is None:\n",
        "      model = create_model(x_data_train[0], dense1, lstm1, lstm2, lstm3)\n",
        "      # draw model to PNG\n",
        "      keras.utils.plot_model(model, to_file = working_dir + '/model.pdf', show_shapes = True)\n",
        "      # model training\n",
        "      print(f'\\n### training with {permutation[0]}, {len(x_data_train)} inputs, {len(x_data_val) if x_data_val is not None else 0} validation')\n",
        "      callbacks = [keras.callbacks.TensorBoard(log_dir + f'_{perm_index + 1}', histogram_freq = 1)]\n",
        "      if earlystop:\n",
        "        callbacks.append(keras.callbacks.EarlyStopping('val_accuracy', min_delta = 0.001, patience = earlystop, restore_best_weights = True, verbose = 1))\n",
        "      # train\n",
        "      start_time = time.monotonic()\n",
        "      history = model.fit(x_data_train, y_data_train, epochs = epochs,\n",
        "        validation_data = (x_data_val, y_data_val) if x_data_val is not None else None,\n",
        "        callbacks = callbacks)\n",
        "      time_train = time.monotonic() - start_time\n",
        "    else:\n",
        "      # model must match with dataset parameters\n",
        "      model = keras.models.load_model(load_model)\n",
        "      history = None\n",
        "      time_train = 0\n",
        "\n",
        "    # model test\n",
        "    if subjs_test:\n",
        "      x_data_test, y_data_test, _ = partition_data(subjs_test[perm_index] if type(subjs_test[0]) == tuple else subjs_test)\n",
        "      if pca:\n",
        "        x_data_test, _ = reduce_matrix(x_data_test, Vpca)\n",
        "        y_data_test = adjust_size(x_data_test, y_data_test)\n",
        "      print(f'\\n### testing with {subjs_test[perm_index] if type(subjs_test[0]) == tuple else subjs_test}, {len(x_data_test)} inputs')\n",
        "      start_time = time.monotonic()\n",
        "      eval_metrics = model.evaluate(x_data_test, y_data_test)\n",
        "      time_test = time.monotonic() - start_time\n",
        "    else:\n",
        "      eval_metrics = [0., 0.]\n",
        "    if write_report:\n",
        "      write_values()\n",
        "    if save_model:\n",
        "      # save in both directory and h5 formats (we had problems with both of them sometimes)\n",
        "      model_file_name = f'{working_dir}/{file_id}model_w{window:04d}_o{overlap:03d}_d{decimation:03d}_e{epochs}_t{round(eval_metrics[1] * 10000)}'\n",
        "      #model.save(model_file_name)\n",
        "      model.save(model_file_name + '.h5')\n",
        "  if write_report:\n",
        "    out_f.close()\n",
        "\n",
        "  return model, x_data_test, y_data_test, eval_metrics[1]  # can be needed by other blocks\n"
      ],
      "metadata": {
        "id": "NugCn0y615kI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"---\n",
        "**Start of actual program blocks:**\n",
        "\"\"\"\n",
        "\n",
        "# create dataset, create model, train and test\n",
        "# if __name__ == '__main__':\n",
        "dense1 = 0\n",
        "lstm1 = 8\n",
        "lstm2 = 8\n",
        "lstm3 = 0\n",
        "\n",
        "window = 256\n",
        "overlap = window // 2\n",
        "oversample = True\n",
        "decimation = 0\n",
        "pca = True  # compute PCA on full data matrix\n",
        "rpca = True  # compute RPCA before PCA\n",
        "spikes = 1/500\n",
        "rpca_mu = 0.1\n",
        "\n",
        "subjs_train_perm = ( (tuple(i for i in range(2, 10)) + tuple(i for i in range(20, 30)), ()), )\n",
        "# subjs_train_perm = ( (tuple(i for i in range(2, 15)) + tuple(i for i in range(18, 35)), ()), )\n",
        "subjs_test = (0, 1, 15, 16, 17)  # 2 for N, 3 for AD\n",
        "epochs = 10\n",
        "\n",
        "  # if decimation:\n",
        "  #   window //= decimation\n",
        "  #   overlap //= decimation\n",
        "\n",
        "x_data, y_data, subj_inputs = create_dataset(window, overlap, decimation)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QbV71jUwRtZ",
        "outputId": "a4a5bcd1-6422-4ada-886b-24a0f431fef0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(('01', 'N'), ('02', 'N'), ('03', 'N'), ('04', 'N'), ('05', 'N'), ('06', 'N'), ('07', 'N'), ('08', 'N'), ('09', 'N'), ('10', 'N'), ('11', 'N'), ('12', 'N'), ('13', 'N'), ('14', 'N'), ('15', 'N'), ('01', 'AD'), ('02', 'AD'), ('03', 'AD'), ('04', 'AD'), ('05', 'AD'), ('06', 'AD'), ('07', 'AD'), ('08', 'AD'), ('09', 'AD'), ('10', 'AD'), ('11', 'AD'), ('12', 'AD'), ('13', 'AD'), ('14', 'AD'), ('15', 'AD'), ('16', 'AD'), ('17', 'AD'), ('18', 'AD'), ('19', 'AD'), ('20', 'AD'))\n",
            "\n",
            "### creating dataset\n",
            "\n",
            "tot samples: 5954304\n",
            "x_data: (46483, 256, 16)\n",
            "y_data: (46483, 1)\n",
            "windows per subject: [868, 759, 739, 1560, 1139, 910, 1256, 1879, 1562, 1136, 1130, 1087, 1109, 1498, 1285, 1384, 1430, 1440, 1525, 1329, 1491, 1574, 1662, 1347, 1471, 1596, 1143, 1121, 1539, 1436, 1328, 1544, 1154, 1164, 1888]\n",
            "class distribution: [17917, 28566]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model, x_data_test, y_data_test, test_acc = train_session(save_model = False, earlystop = 0)  # returned variables can be optionally used by other blocks of code\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rAIBw4UwzVF6",
        "outputId": "a4118493-edc9-49c4-e42b-ad0649c81abb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "class distribution (training subset): [10181, 14380]\n",
            "After oversampling (training subset):\n",
            "x_data_train: (28760, 256, 16)\n",
            "y_data_train: (28760, 1)\n",
            "class distribution: [14380, 14380]\n",
            "\n",
            "Performing (R)(MS)PCA...\n",
            "Auto tol: 0.0009507554366505457 used tol: 5e-06\n",
            "mu 0.1 lambda 0.0017022170495076935\n",
            "iteration: 1, error: 94.94793486696643, ||S||: 94.88110235008492\n",
            "iteration: 2, error: 6.565819780371327, ||S||: 185.3408196499094\n",
            "iteration: 3, error: 4.42453273528766, ||S||: 273.0050906757732\n",
            "iteration: 4, error: 4.546682015769854, ||S||: 357.5900098476372\n",
            "iteration: 5, error: 4.930932859476592, ||S||: 438.676217439168\n",
            "iteration: 6, error: 5.34899012602163, ||S||: 515.8078198338236\n",
            "iteration: 7, error: 5.735833941831613, ||S||: 588.5517249696509\n",
            "iteration: 8, error: 6.046589607713281, ||S||: 656.5797820127156\n",
            "iteration: 9, error: 6.262119815175569, ||S||: 719.7525340133992\n",
            "iteration: 10, error: 6.398718700035524, ||S||: 778.1572362585783\n",
            "||A,L,S||: 9507.554366505457 9311.192378083506 778.1572362585783\n",
            "PCA truncation 256 -> 50\n",
            "x_data_train: (21570, 50, 16)\n",
            "y_data_train: (21570, 1) [10820, 10750]\n",
            "x_data_val: (7190, 50, 16)\n",
            "y_data_val: (7190, 1) [3560, 3630]\n",
            "\n",
            "### creating model\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm1 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)               │             \u001b[38;5;34m800\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop2 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m8\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm2 (\u001b[38;5;33mLSTM\u001b[0m)                         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │             \u001b[38;5;34m544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop3 (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense2 (\u001b[38;5;33mDense\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │              \u001b[38;5;34m18\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ drop3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,362\u001b[0m (5.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,362</span> (5.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,362\u001b[0m (5.32 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,362</span> (5.32 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "### training with (2, 3, 4, 5, 6, 7, 8, 9, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29), 21570 inputs, 7190 validation\n",
            "Epoch 1/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 43ms/step - accuracy: 0.6215 - loss: 0.5988 - val_accuracy: 0.9135 - val_loss: 0.2397\n",
            "Epoch 2/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 40ms/step - accuracy: 0.9247 - loss: 0.2223 - val_accuracy: 0.9346 - val_loss: 0.1779\n",
            "Epoch 3/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 40ms/step - accuracy: 0.9515 - loss: 0.1495 - val_accuracy: 0.9606 - val_loss: 0.1166\n",
            "Epoch 4/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 38ms/step - accuracy: 0.9644 - loss: 0.1141 - val_accuracy: 0.9648 - val_loss: 0.1051\n",
            "Epoch 5/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 40ms/step - accuracy: 0.9696 - loss: 0.1008 - val_accuracy: 0.9683 - val_loss: 0.0939\n",
            "Epoch 6/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 39ms/step - accuracy: 0.9733 - loss: 0.0889 - val_accuracy: 0.9694 - val_loss: 0.0921\n",
            "Epoch 7/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9748 - loss: 0.0815 - val_accuracy: 0.9711 - val_loss: 0.0899\n",
            "Epoch 8/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9787 - loss: 0.0749 - val_accuracy: 0.9744 - val_loss: 0.0841\n",
            "Epoch 9/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 39ms/step - accuracy: 0.9796 - loss: 0.0715 - val_accuracy: 0.9733 - val_loss: 0.0890\n",
            "Epoch 10/10\n",
            "\u001b[1m675/675\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 39ms/step - accuracy: 0.9797 - loss: 0.0689 - val_accuracy: 0.9752 - val_loss: 0.0804\n",
            "\n",
            "### testing with (0, 1, 15, 16, 17), 5881 inputs\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9353 - loss: 0.2276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model test only\n",
        "# if False and __name__ == '__main__':\n",
        "print(f'### testing with {len(x_data_test)} inputs')\n",
        "eval_metrics = model.evaluate(x_data_test, y_data_test)\n"
      ],
      "metadata": {
        "id": "I2DndfcMwfLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f079dcf3-12f4-498e-cbd1-393bb806f903"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### testing with 5881 inputs\n",
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9353 - loss: 0.2276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # create confusion matrix\n",
        "# if False and __name__ == '__main__':\n",
        "import pandas as pd\n",
        "import seaborn\n",
        "y_pred = np.argmax(model.predict(x_data_test), axis=-1)\n",
        "con_mat = tf.math.confusion_matrix(labels = y_data_test, predictions = y_pred).numpy()\n",
        "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis = 1)[:, np.newaxis], decimals = 2)\n",
        "classes = ['N', 'AD']\n",
        "con_mat_df = pd.DataFrame(con_mat_norm, index = classes, columns = classes)\n",
        "figure = plt.figure(figsize = (5, 5))\n",
        "seaborn.heatmap(con_mat_df, annot = True, cmap = plt.cm.Blues)\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.tight_layout()\n",
        "plt.savefig(working_dir + '/confusion_matrix.eps', format='eps')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RaDRLf3CweU0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "outputId": "b42071a2-be82-4500-dfd6-d15d34f99d39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m184/184\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQTbc++CDYM+SKml+qUCly",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}